# üß† Scraper con IA para sitios web de noticias econ√≥micas

Este proyecto implementa un scraper generalizado potenciado por inteligencia artificial, dise√±ado para extraer informaci√≥n √∫til desde p√°ginas web din√°micas, incluso cuando los datos no est√°n estructurados de forma clara. Utiliza **Selenium** para la captura din√°mica de HTML y modelos de lenguaje de **Azure OpenAI** (como GPT o Gemini) para procesar y estructurar la informaci√≥n de forma flexible.

---

## üöÄ Descripci√≥n general

El scraper accede a sitios web de noticias econ√≥micas, descarga el HTML completo con Selenium, y lo divide en bloques analizables. Luego, utiliza modelos de lenguaje IA para interpretar esos bloques y extraer contenido relevante como t√≠tulos, fechas, enlaces y fuentes.

Este enfoque h√≠brido combina la confiabilidad del scraping tradicional con la adaptabilidad de los modelos LLM.

---

## üß† Scraping asistido por Inteligencia Artificial

En ciertos escenarios, especialmente cuando se requiere procesar grandes vol√∫menes de HTML sin estructura clara, o cuando los datos se presentan de forma inconsistente, las t√©cnicas tradicionales de scraping pueden no ser suficientes.

Adem√°s, muchos modelos de lenguaje actuales, como **Gemini**, **GPT** o los modelos de **Azure OpenAI**, **no permiten navegaci√≥n web directa v√≠a API**, lo que plantea desaf√≠os adicionales si se desea automatizar tareas de extracci√≥n con ayuda de IA.

### ‚úÖ Soluci√≥n propuesta: combinaci√≥n de scraping + IA

Este proyecto implementa un enfoque mixto que:

- Accede a sitios web (est√°ticos o din√°micos) mediante **Selenium**.
- Maneja bloqueos utilizando headers aleatorios, tiempo de espera y rotaci√≥n de agente de usuario.
- Extrae el HTML completo de las p√°ginas indicadas.
- Filtra los elementos correspondientes a **listas o bloques de noticias**.
- Divide los HTMLs en **bloques m√°s peque√±os** para ajustarse a los l√≠mites de tokens de los LLM.
- Env√≠a estos bloques a un modelo IA (como GPT-4 o Gemini 1.5 Flash) para su interpretaci√≥n.
- El modelo responde con **contenido estructurado**, facilitando su posterior an√°lisis o almacenamiento.

‚ö†Ô∏è Este enfoque **no reemplaza** al scraping tradicional, sino que lo **complementa** cuando la l√≥gica de extracci√≥n es compleja o inconsistente.

---

## ‚öôÔ∏è Procesamiento paso a paso

1. **Descarga HTML**: Se utiliza `selenium` para abrir sitios, esperar contenido din√°mico y capturar el HTML completo.
2. **Reducci√≥n de HTML**: Se filtran listas de inter√©s desde el HTML crudo.
3. **Divisi√≥n en bloques**: Se fragmenta el contenido para cumplir con los l√≠mites del modelo IA.
4. **Extracci√≥n con IA**: Cada bloque es enviado a un modelo LLM que responde con contenido estructurado en JSON.
5. **Almacenamiento**: Los resultados se guardan localmente como `.json`, `.csv` o `.parquet` y se pueden subir a **Azure Data Lake**.

---

## ‚ñ∂Ô∏è Uso

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```
### 2. Configurar credenciales
Crear un archivo .env con las siguientes variables:

```STORAGE_ACCOUNT_NAME = ""
STORAGE_ACCOUNT_KEY = ""
AZURE_ENDPOINT = ""
AZURE_API_KEY = ""
AZURE_API_VERSION =  ""
IA_MODEL_NAME = ""
DEPLOYMENT = ""
```

### 3. Ejecutar el scraper
```
python main.py
```